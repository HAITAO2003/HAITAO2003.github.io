<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Haitao Wang - AI Researcher</title>
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
</head>
<body>
<header>
    <div class="container">
        <nav>
            <a href="index.html" class="nav-logo">Haitao Wang</a>
            <div class="nav-links">
                <a href="index.html">Home</a>
                <a href="blog.html">Blog</a>
                <a href="projects.html">Projects</a>
                <a href="resources.html">Resources</a>
                <a href="forum.html">Forum</a>
            </div>
        </nav>
    </div>
</header>

<div class="container">
    <!-- Hero Section -->
    <div class="hero-section">
        <div class="hero-bg-animation"></div>
        <div class="hero-content-wrapper">
            <img src="images/profile.jpeg" alt="Haitao Wang" class="profile-image">
            <div class="hero-content">
                <h1 class="hero-title">Hi, I'm Haitao Wang</h1>
                <div class="hero-subtitle"> Final Year CS Student at NUS</div>
                <p class="hero-description">
                    Passionate about reinforcement learning and its applications to automated portfolio management
                    and high-frequency trading systems. I believe in the power of agents that learn through interaction
                    and can achieve superhuman performance in complex decision-making tasks.
                </p>
                <div class="hero-links">
                    <a href="mailto:e1070551@u.nus.edu" class="hero-link"><i class="fas fa-envelope"></i> Email</a>
                    <a href="https://github.com/HAITAO2003" class="hero-link"><i class="fab fa-github"></i> GitHub</a>
                    <a href="#research" class="hero-link"><i class="fas fa-microscope"></i> Research</a>
                </div>
            </div>
        </div>
    </div>

    <!-- About Section -->
    <section class="about-section">
        <div class="section-content">
            <h2 class="section-title">About Me</h2>
            <div class="about-grid">
                <div class="about-text">
                    <p> I am a final-year Computer Science undergraduate at the National University of Singapore (NUS),
                        specializing in Artificial Intelligence with a concentration in reinforcement learning. My research
                        focuses on the intersection of RL and quantitative finance, where I model trading environments as complex,
                        partially observable sequential decision-making problems under uncertainty.
                    </p>
                    <p> My foundational experience in RL began with undergraduate research, where I investigated both
                        model-free and model-based approaches. Over time, I developed a strong interest in deep reinforcement
                        learning and its ability to handle high-dimensional state spaces and continuous action domains.
                        I have since worked with a range of algorithms model-free policy gradient methods
                        such as PPO, SAC, and TD3 to model-based POMDP algorithms such as SLAC and TD-MPC2 â€” often integrating
                        them into simulated market environments with realistic execution constraints and specialised networks
                        for time-series data processing.
                    </p>
                    <p> Currently, I am developing adaptive trading agents that leverage state-of-the-art meta-reinforcement
                        learning techniques combined with transformer-based encoder. My goal is to design agents
                        capable of rapidly adapting to regime shifts and non-stationary dynamics in financial markets.
                        Through this work, I aim to demonstrate the viability of RL in solving real-world sequential
                        decision-making problems in domains where environment dynamics are complex, stochastic,
                        and evolving. </p>
                </div>
                <div class="skills-card">
                    <h3>Technical Skills</h3>
                    <div class="skill-tags">
                        <span class="skill-tag">Python</span>
                        <span class="skill-tag">PyTorch</span>
                        <span class="skill-tag">JAX</span>
                        <span class="skill-tag">OpenAI Gym</span>
                        <span class="skill-tag">Stable Baseline 3</span>
                        <span class="skill-tag">NumPy</span>
                        <span class="skill-tag">Representation Learning</span>
                        <span class="skill-tag">Pandas</span>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Research Interests -->
    <section id="research" class="research-section">
        <div class="section-content">
            <h2 class="section-title">Research Interests</h2>
            <div class="research-grid">
                <div class="research-card">
                    <div class="research-icon"><i class="fas fa-brain"></i></div>
                    <h3>Model-Free RL</h3>
                    <p>Exploring and adapting various online-RL algorithms such as PPO, SAC, TD3 for complex trading environments.</p>
                </div>
                <div class="research-card">
                    <div class="research-icon"><i class="fas fa-project-diagram"></i></div>
                    <h3>Model-Based RL</h3>
                    <p>Investigating world models and planning algorithms that can learn environment dynamics for sample-efficient learning.</p>
                </div>
                <div class="research-card">
                    <div class="research-icon"><i class="fas fa-sync-alt"></i></div>
                    <h3>Meta-RL</h3>
                    <p>Developing algorithms that can quickly adapt to new tasks and environments with minimal experience.</p>
                </div>
                <div class="research-card">
                    <div class="research-icon"><i class="fas fa-chart-line"></i></div>
                    <h3>RL in Finance</h3>
                    <p>Applying RL to portfolio optimization, algorithmic trading, and risk management in financial markets.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Recent Blog Posts -->
    <section class="blog-section">
        <div class="section-content">
            <h2 class="section-title">Recent Blog Posts</h2>
            <div class="recent-posts" id="home-recent-posts">
                <!-- Blog posts will be dynamically loaded here -->
            </div>
            <div class="blog-cta">
                <a href="blog.html" class="btn-primary">View All Posts <i class="fas fa-arrow-right"></i></a>
            </div>
        </div>
    </section>
</div>

<footer>
    <div class="container">
        <p>&copy; 2024 Haitao Wang. All rights reserved.</p>
    </div>
</footer>

<script src="js/main.js"></script>
</body>
</html>